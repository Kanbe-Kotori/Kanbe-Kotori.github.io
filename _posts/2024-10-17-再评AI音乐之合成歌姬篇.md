---
layout: post
category: diaries
title: 再评AI音乐之合成歌姬篇
excerpt: 魔幻平行世界与屎味巧克力
---

&emsp;&emsp;在上一期相关内容的杂谈[《关于AI作曲》](../notes/关于AI作曲)中，我已经对以Suno AI为代表的AI编曲音乐进行了一波锐评。时至今日，当我再次边写代码边在b站欣赏AI音乐艺术 ~~（赤石）~~ 时，才突然发觉自己之前竟然遗漏了AI音乐的另一个重要分支：AI合成歌姬，于是决定随便写点东西补充一下。不过，关于这方面感觉可写的东西确实不多，实在不够撑起一篇完整的杂谈，最终决定就写一篇日寄随便聊聊好了。

&emsp;&emsp;“AI合成歌姬”这个名字虽然听起来有点玄乎，其实从原理上说倒也不难理解。众所周知，一段语音内包含的信息可以分为“内容特征”和“音色特征”两部分，其中前者指的是语音的文字内容、发音和语速等等，而后者则承载了发声者所特有的某些声音特质。近年来，随着深度学习模型的发展和算力的大幅提升，如今的某些模型比如[So-VITS](https://github.com/svc-develop-team/so-vits-svc)已经可以做到将“内容特征”和“音色特征”分离，然后通过混合一段语音的“内容特征”和另一段语音的“音色特征”的方式，就可以实现将某人说的话转换为由另一人说出的效果。不过，虽 然这个原理说起来还算直观，但实际用到的深度学习模型还是比较复杂的，涉及梅尔谱转换、扩散模型、流式模型等多个不太相关的领域。虽然这些东西我也不是不会，但为了避免读者睡着，在这里还是不做具体讲解，暂且把它当做黑盒看待。

&emsp;&emsp;在拥有了如此方便的工具之后，我们就可以将其应用到各种领域当中。其中，最棘手的问题可能是声音造假带来的安全问题，尤其是和身份认证有关的安全攻防问题，不过这个话题与本文无关，所以暂且按下不表。而如果把它应用到音乐领域，那么声音的“内容特征”和“音色特征”则可以大致对应“歌词”和“歌手”。这样一来，从理论上讲我们就能做到让任何歌手去演唱任何歌曲，并且语言和风格上的限制都不再是问题，唯一的限制可能只在于你的想象力——比如，腾格尔大爷演唱的《爱你》会是[什么样子](www.bilibili.com/video/BV1ym4y1h7v9)？如果把思路再放开一点，我们甚至还能让已故的歌手“复活”，然后合成出他们在真实历史中根本不可能见到过、可能相差几个时代的曲目，比如邓丽君版本的《泪桥》又会是[什么样子](www.bilibili.com/video/BV1PW421R7LD)？在语音合成模型诞生之前，我认为这些内容都是人类根本难以想象的。

&emsp;&emsp;听完这些“奇妙组合”的音乐后，我忽然产生了一个荒诞的念头：在某个与我们生活的世界有着微妙差别的平行宇宙中，这些音乐是否可能真的存在过？或许在那里，腾格尔的《爱你》早已传唱街头？而比我们的世界中晚出生了几十年的邓丽君，可能刚刚凭借《泪桥》一夜成名？从这个角度上说，VITS又是否可以被看做是一种“与平行宇宙沟通的工具”？这当然只是一种美好的遐想，但它也确实让我们得以一窥那些从未发生、却仿佛可能存在的音乐瞬间。这大概也能算是一种科技的浪漫了吧。

&emsp;&emsp;当然，并非所有人都在追求这种浪漫，有些人则是朝着搞笑的方向一路狂奔。比如，同样是这首《泪桥》，但当演唱者换成 ~~音道炎的~~ 著名游戏主播“异灵术老师”的时候，[那个效果](www.bilibili.com/video/BV1T2421w74X)实在是让人难以评价。虽然确实不能说是一无是处——毕竟声音的“内容特征”不仅包括歌词，多少也保留了音准和情感——但异佰老师的音色也确实过于出戏，即使是这种唱功也没能成功抢救。如果说原曲是一块巧克力，但音源是屎的话，那这玩意简直就是一块完美融合的屎味巧克力——按照粉皮猪老师那样的声音条件，在正常世界线下大概率是不会去学唱歌的，就算真是苦学多年学有所成之后在直播间整活自己唱，大概率也不会投入什么真情实感，大家最多也就是听一乐。而现在，这种香与臭的结合简直就像是一块屎味巧克力，与其说是作者打开了平行世界的大门，不如说更像是某种精神管制药品吃多了。

&emsp;&emsp;无论如何，如今的声音合成技术都可以说是一次巨大的进步。相比过去“活字印刷”式的人力Vocaloid，如今的“AI歌姬”无论是在效率还是质量上都已经是突飞猛进。至于这些技术未来的发展，以及可能带来的问题（比如安全问题和版权问题），就交给后来者们去解决吧。

&emsp;&emsp;以上。
